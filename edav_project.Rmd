---
title: "EDAV Project"
output:
  html_document: default
  pdf_document: default
group: Costa, Yannis, Eric, Kai
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      cache = TRUE)
```

```{r libraries}
# import libraries
library(tidyverse)
library(lubridate)
scale_colour_continuous <- scale_colour_viridis_c
theme_set(theme_bw())
```
# Outline

# Introduction

# Description of data

# Analysis of data quality
## Pipeline
[__Here__](https://github.com/Ecboxer/BKTV_Project/blob/master/pipeline_opt.R) is our script.  
Having downloaded the data as three csv files (one for each of October, November and December 2017) we wrote an R script to construct features for departure and arrival delays and output two csvs, one of the full dataset and another of a representative random sample.  
The steps of the pipeline are as follows:  
* Bind the csv files of October, November and December flights by row.  
* Rename the columns of the combined dataframe for easier access.  
* Format departure and scheduled departure times from 'HH:MM' to 'YYYY:mm:dd HH:MM:00' and take their difference to get find departure delay, in minutes.  
* Repeat the previous step for arrival and scheduled arrival times to find arrival delays.  
Since the full data set contains 1.4 million rows, in the interest of quick computations and visualizations in the exploratory data analysis phase, we took a random sample of 150 000 rows from the processed data. 150 000 was arrived at as a compromise between the processing speed of a small sample and the representativeness of a large one.

```{r load data}
#Import sampled and full datasets
df_sample <- read_csv('cleanest_sample.csv')
df <- read_csv('clean.csv')
```

## Missing values
```{r missing values}
colSums(is.na(df)) / nrow(df)
```

Of the features included in our final dataset, departure time, arrival time, departure delay and arrival delay were missing values for 0.7% of observations. Cancellation code had missing values for 99% of observations.

```{r delay missing values}
extracat::visna(df)
```

The dominant missing data pattern is for observations to be missing only cancellation code. Infrequently, observations are missing departure and arrival times, but we felt that all observations missing either of those values could be removed without losing information about delay durations.

```{r cancellation missing values}
df %>% filter(is.na(canc_code) & cancelled == 1) %>% nrow()
```

No observations missing a cancellation code can easily be found to have been incorrectly entered, because there are no cases in which cancellation code is missing but the data tells us that the flight was actually cancelled.

```{r cancellation look}
df %>% filter(!is.na(canc_code)) %>%
  group_by(canc_code) %>%
  summarise(n = n()) %>%
  ggplot() +
  geom_bar(aes(reorder(canc_code, -n), n), color='#774184', stat='identity') +
  xlab('canc_code')
```

Cancellation codes are encoded by cause of cancellation as follows: A Carrier, B Weather, C National Air System, D Security. Security cancellations accounted for a tiny proportion while weather cancellations were the most frequent. We opted to forgo further investigation of cancellations. Since these flights never departed, there is no delay information from any of these observations in the dataset.

## Explain metadata
The final features are as follows:  
* date: flight date in the format YYYY-mm-dd  
* carrier: a unique two-letter carrier code for each airline, ie 'AA' for American Airlines  
* flight_num: a unique four-digit number for each flight  
* origin: a unique five-digit number for each origin airport, with all of these located in New York State  
* dest: similar to origin but for each destination airport and located in any US state  
* dest_state: a two-digit code for the flight destination state or US territory  
* sched_dep: scheduled departure time in the format YYYY-mm-dd HH:MM:00  
* dep: actual departure time in the same format  
* sched_arr: schedulaed arrival time in the same format  
* arr: actual arrival time in the same format  
* cancelled: indicator of flight cancellation, with 1 corresponding to a cancelled flight and 0 otherwise  
* canc_code: specifies the reason for cancellation  
* distance: distance between origin and destination airports, in miles  
* weekday: a string corresponding to the day of the week of the flight date  
* dep_delay: departure delay, in minutes. Negative values correspond to flights that departed before schedule, positive values with flights that departed after they were scheduled  
* arr_delay: similar to dep_delay but for arrival delay  

## Filtering
For the remainder of the data exploration we removed observations with missing values in the departure and arrival delay features. Then, we removed those observations with departure or arrival delay less than 2 hours or greater than 6 hours. In processing the data there were a small percentage of flights which were scheduled to depart/arrive before midnight but had actual times after midnight (or were scheduled for after midnight but had actual times before). As a consequence of our method for calculating delay (taking the difference of scheduled and actual times), those observations came out with delays of magnitude plus-minus 1440 (the number of minutes in one day). Keeping those observations would introduce extreme outliers. Since this happened to about 1% of the data we decided to exclude these observations from the analysis.
```{r exclude outliers}
df %>% 
  filter(dep_delay < -1200 | dep_delay > 1200 | arr_delay < -1200 | arr_delay > 1200) %>% 
  nrow() / nrow(df)
```

```{r filtering illustration, eval = FALSE}
df_sample %>% 
  ggplot() +
  geom_point(aes(dep_delay, flight_num), alpha=.2, shape=1)
```
![](dep_delay.png)
The decision to keep data with delays in the range [-120, 720] was in part due to the roundess of those values. In addition, the delay data tended to fall within that range so filtering here will serve to remove outliers from the remainder of our analysis.

```{r clean data}
# Delete NA rows, which indicate flight cancellations
df_sample <- df_sample %>%
  filter(!is.na(dep_delay) & !is.na(arr_delay))
df <- df %>%
  filter(!is.na(dep_delay) & !is.na(arr_delay))

# Subset data with relevent dep_delay and arr_delay values
df_sample <- df_sample %>%
  filter(arr_delay >= -120 & arr_delay <= 720 & dep_delay >= -120 & dep_delay <= 720)
df <- df %>%
  filter(arr_delay >= -120 & arr_delay <= 720 & dep_delay >= -120 & dep_delay <= 720)
```

# Main analysis (Exploratory Data Analysis)
## Destination
```{r number of destinations}
df$dest %>% unique() %>% length() #How many airports in the data?
```

To begin exploring the data on destination, with 300 unique values, we first construct a dataframe grouped by destination and with features for the number of flights, the total departure delay and the mean departure delay.
```{r destination frequency}
df_n <- df %>% group_by(dest) %>% 
  summarise(n = n(),
            total_delay = sum(dep_delay),
            avg_delay = total_delay / n) %>% 
  arrange(desc(n))
```

With the dataframe in hand, first we will look at those destinations with the most flights, more than 20 000 over the period.
```{r destination cleveland}
df_n %>% filter(n > 20000) %>% ggplot() +
  geom_point(aes(reorder(dest, avg_delay), avg_delay, size=n, color=avg_delay)) +
  coord_flip() + scale_color_viridis_c()
```

11618 Newark Liberty International stands out as having the highest average delay of the lot. 14771 San Francisco International has a smaller average delay than Newark, but it stands out among those airports with more than 40 000 flights. Apart from San Francisco these airports have average delays in the neightborhood of five minutes. It is also noticeable that none of the most frequent destinations have a negative average delay.

```{r destination negative delay}
df_n %>% filter(avg_delay < 0) %>% ggplot() +
  geom_point(aes(reorder(dest, avg_delay), avg_delay, size=n, color=avg_delay)) +
  coord_flip()
```

Here we looked at those destinations with negative average delays. According to our size scale, the frequency of flights to these airports is more than an order of magnitude lower than in the previous plot. Two airports stand out in terms of average delay, 10165 Adak Island, Alaska and 10754 Barrow, Alaska. 
```{r destination zero delay}
df_n %>% filter(avg_delay < 1 & avg_delay > -1) %>% ggplot() +
  geom_point(aes(reorder(dest, avg_delay), avg_delay, size=n, color=avg_delay)) +
  coord_flip()
```

Among those airports with average delays within one minute of zero, the number of flights also tends to be small, no more than 3 000.
```{r destination high frequency}
df_n %>% filter(avg_delay > 10) %>% ggplot() +
  geom_point(aes(reorder(dest, avg_delay), avg_delay, size=n, color=avg_delay)) +
  coord_flip()
```

When we filter to those airports with average delays greater than ten minutes, airport 11618 Newark stand out as by far the most popular destination in this bracket. As with the negative delay visualization, there are a small number of outliers in terms of average delay:  
* 13388 Mammoth Lakes, California  
* 15295 Toledo, OH  
* 13964 North Bend/Coos Bay, Oregon  
* 10372 Aspen, Colorado  
Mammoth Lakes and Aspen are both ski resort towns so it might be interesting to look at the average delays in the summer to see if there is a reversion to the mean during warmer months.  

# Executive summary (Presentaion-style)

## Daily Departure Delays
[__Here__](https://bl.ocks.org/ecboxer/6be5cf6fc44449823e08ca5f1b443935) is a visualization of the average departure delay for each date in the dataset. Each month is shown as a calendar heatmap with each week in a row starting on Monday and ending on Sunday. We used a Value Suppressing Uncertainty Scale (VSUP) which decreases the number of distinct colors according to increasing uncertainty, measured in standard mean error of delay time. Hover over a tile to show the precise departure delay.  
Starting in October, we do not see a clear pattern to delays. Tuesdays and Wednesdays have low departure delays for all but one week, the 24th for Tuesdays and the 11th for Wednesdays. In November, there is a similarly varied distribution to delays. Note the scale changes across months, so the 3rd of November is encoded as high delay with a 10 minute average while the 12th of October has a similar average but lies closer to the middle of that month's distribution. The clearest pattern in December is the split between the beginning of the month and the final two weeks. After the 18th, delays are almost all on the higher-end, with the 30th having an average delay of 20 minutes (but also the highest uncertainty).  

## Weekly Departure Delays
[__Here__](https://bl.ocks.org/ecboxer/221d818a4b9fad4feb0ab14e7ca704a1) is a visualization of the average departure delay grouped by day of the week and hour of departure. It was constructed with the same VSUP scale as the daily departure delay visualization. Again, hovering over a tile shows the precise departure delay.  
There are two patterns here: the distinction between weekdays and weekends, and an increase in delay length as a given day progresses. Weekends have a longer period of dark-blue than weekdays (corresponding to delays in the range of 3-9 minutes), and even in the hour before midnight do not reach the same magnitude of delay as do weekdays.  
Across all days, until 9am average delays are small or negative. Afterwards there is a gradual increase in delays until we see an average delay length of 38 minutes in flights departing before midnight on Mondays.  
Note: the choice was made to start the x-axis at 4am since at all previous times the standard mean errors were at least 0.1875 and their values were thus suppressed by our scale.

# Interactive component

# Conclusion

#### Future direction
* Cancellations, ie does the presence of cancelled flights increase the delays for flights that did depart?
* Other origin airports
* Full year/several years